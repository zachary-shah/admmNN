{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "from scipy.linalg import block_diag"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size Guide:\n",
    "\n",
    "* $n$ - number of training examples\n",
    "* $d$ - feature dimension\n",
    "* $r$ - rank of $X$\n",
    "* $P$ - total enumerations of hidden neurons / ReLU activations\n",
    "* $P_S$ - number of hidden neurons / samples of $D_i$ matrices\n",
    "\n",
    "Matrices\n",
    "* $X \\in \\mathbb{R}^{n \\times d}$ - training data matrix\n",
    "* $D_i \\in \\mathbb{R}^{n \\times n}, \\ i = 1,\\dots,P_S$ - diagonal matrices sampling hidden layer activations\n",
    "* $F_i = D_i X \\in \\mathbb{R}^{n \\times d}, \\ i = 1,\\dots,P_S$\n",
    "* $F = \\begin{bmatrix} F_1 & \\dots & F_{P_S} & -F_1 & \\dots & -F_{P_S} \\end{bmatrix} \\in \\mathbb{R}^{n \\times (2 d P_S)}, \\ i = 1,\\dots,P_S$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "### user inputs \n",
    "n,d = 100,5\n",
    "\n",
    "# X - data matrix in n x d\n",
    "X = np.random.randn(n,d)\n",
    "# y are targets\n",
    "y = np.random.randn(n,1)\n",
    "\n",
    "r = np.linalg.matrix_rank(X)\n",
    "\n",
    "# number of hidden neurons in convex network\n",
    "P_S = 10\n",
    "\n",
    "# parameters (TODO: parameterize)\n",
    "rho = 1e-5\n",
    "step = 1e-5\n",
    "beta = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: figure out better way to sample D matrices\n",
    "\n",
    "h = np.random.randn(d, P_S)\n",
    "\n",
    "# TODO: assert that no duplicate columns\n",
    "# n x P_S matrix, where each column is the diagonal entries for one D matrix\n",
    "d_diags = X @ h >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather F and G\n",
    "\n",
    "# # F is P_S x n x d. F[i] = F_i in (n x d)\n",
    "# F = np.swapaxes(\n",
    "#         np.swapaxes(\n",
    "#             np.dstack([np.diag(d_diags[:,i].astype('uint8')) @ X for i in range(P_S)]),\n",
    "#             2, 0),\n",
    "#     1, 2)\n",
    "\n",
    "# F here is n x (2d*P_S) like paper\n",
    "F = np.hstack([np.hstack([np.diag(d_diags[:,i].astype('uint8')) @ X for i in range(P_S)]),\n",
    "    np.hstack([-np.diag(d_diags[:,i].astype('uint8')) @ X for i in range(P_S)[::-1]])])\n",
    "\n",
    "\n",
    "# G is block diagonal 2*n*P_S x 2*d*P_s\n",
    "G = block_diag(*[(2 * np.diag(d_diags[:,i].astype('uint8')) - np.eye(n)) @ X for i in range(P_S)] * 2)\n",
    "\n",
    "# dual variables\n",
    "lam = np.zeros((2*d*P_S,1))\n",
    "nu = np.zeros((2*d*P_S,1))\n",
    "\n",
    "# weights\n",
    "\n",
    "# u contains u1 ... uP, z1... zP in one long vector\n",
    "u = np.zeros((d * P_S * 2))\n",
    "# v contrains v1 ... vP, w1 ... wP in one long vector\n",
    "v = np.zeros((d * P_S * 2))\n",
    "\n",
    "# slacks\n",
    "s = np.zeros((P_S * n))\n",
    "t = np.zeros((P_S * n))\n",
    "for i in range(P_S):\n",
    "    G_i = (2 * np.diag(d_diags[:,i].astype('uint8')) - np.eye(n)) @ X\n",
    "    # s_i = G_i v_i\n",
    "    s[i] = G_i @ v[i*d:(i+1)*d]\n",
    "    # t_i = G_i w_i\n",
    "    t[i] = G_i @ v[(i+P_S)*d:(i+P_S+1)*d]\n",
    "\n",
    "# precomputes: A in 2dP_s x 2dP_s\n",
    "A = np.eye(2*d*P_S) + F.T @ F / rho + G.T @ G\n",
    "# cholesky factorization\n",
    "L = LA.cholesky(A)\n",
    "\n",
    "b_1 = F.T @ y / rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# updates \n",
    "\n",
    "# update u\n",
    "\n",
    "# updates of v\n",
    "for i in range(P_S):\n",
    "    lam_1i = lam[d*i:d*(i+1)]\n",
    "    v[i] = np.maximum(1 - beta/(rho * LA.norm(u[i] + lam_1i)), 0)\n",
    "    v[i] *= (u[i] + lam_1i)\n",
    "\n",
    "# updates of w\n",
    "for i in range(P_S):\n",
    "    lam_2i = lam[d*(i+P_S):d*(i+P_S+1)]\n",
    "    w[i] = np.maximum(1 - beta/(rho * LA.norm(z[i] + lam_2i)), 0)\n",
    "    w[i] *= (u[i] + lam_2i)\n",
    "\n",
    "# updates on s\n",
    "for i in range(P_S):\n",
    "    s[i] = np.maximum(G[i] @ u[i] + nu[d*i:d*(i+1)], 0)\n",
    "    t[i] = np.maximum(G[i] @ z[i] + nu[d*(i+P_S):d*(i+P_S+1)], 0)\n",
    "\n",
    "# dual updates last\n",
    "lam += lam + step / rho * (u - v)\n",
    "nu += lam + step / rho * (G @ u - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvx-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
