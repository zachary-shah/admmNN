{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from admm_approximate_solver import Approximate_ReLU_ADMM_Solver\n",
    "from relu_utils import squared_loss, classifcation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n train = 1279\n",
      "n test = 320\n"
     ]
    }
   ],
   "source": [
    "# generate toy data trying to fit noisy data to cosine\n",
    "data = pd.read_csv(\"test_data/wineQuality-red.csv\", delimiter=\";\")\n",
    "X = np.array(data)[:,:11]\n",
    "y = np.array(data.quality)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "n_train, d = X_train.shape\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "print(f\"n train = {n_train}\")\n",
    "print(f\"n test = {n_test}\")\n",
    "\n",
    "m = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=11, out_features=10, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=10, out_features=9, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# TODO: solve simple pytorch problem\n",
    "\n",
    "MLP = nn.Sequential(nn.Linear(d, m),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(m, np.max(y)+1))\n",
    "\n",
    "print(MLP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solver doesn't converge well... Things needing fixing right now: \n",
    "\n",
    "- How to choose m, P_S?\n",
    "- How to choose parameters $\\rho$, step=$\\gamma_{\\alpha}$, $\\beta$? \n",
    "- Converting from optimal weights $v, w$ to $u, \\alpha$. Currently loss during training is consistently high but gets lower when calling .predict\n",
    "- Runtime warning - divide by zero in optimizer. need to figure out why / fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 0, loss = 20642.500000000004, acc = 0.0\n",
      "iter = 1, loss = 252.12420344532072, acc = 0.617670054730258\n",
      "iter = 2, loss = 251.9245329826125, acc = 0.6215793588741204\n",
      "iter = 3, loss = 251.8436917007559, acc = 0.6215793588741204\n",
      "iter = 4, loss = 251.81006738670993, acc = 0.6207974980453479\n",
      "iter = 5, loss = 251.79552457465113, acc = 0.6200156372165755\n",
      "iter = 6, loss = 251.7888480383544, acc = 0.6200156372165755\n",
      "iter = 7, loss = 251.78550294310807, acc = 0.6200156372165755\n",
      "iter = 8, loss = 251.78362337074176, acc = 0.6200156372165755\n",
      "iter = 9, loss = 251.7824238757141, acc = 0.6200156372165755\n",
      "iter = 10, loss = 251.78156410041814, acc = 0.6200156372165755\n",
      "iter = 11, loss = 251.78089012526422, acc = 0.6200156372165755\n",
      "iter = 12, loss = 251.78032824031698, acc = 0.6200156372165755\n",
      "iter = 13, loss = 251.77984071058057, acc = 0.6200156372165755\n",
      "iter = 14, loss = 251.7794068266156, acc = 0.6200156372165755\n",
      "iter = 15, loss = 251.77901437109787, acc = 0.6200156372165755\n",
      "iter = 16, loss = 251.77865563263484, acc = 0.6200156372165755\n",
      "iter = 17, loss = 251.77832538152398, acc = 0.6200156372165755\n",
      "iter = 18, loss = 251.77801993442273, acc = 0.6200156372165755\n",
      "iter = 19, loss = 251.77773646587573, acc = 0.6200156372165755\n",
      "iter = 20, loss = 251.77747269128693, acc = 0.6200156372165755\n",
      "iter = 21, loss = 251.7772268019703, acc = 0.6200156372165755\n",
      "iter = 22, loss = 251.77699727359442, acc = 0.6200156372165755\n",
      "iter = 23, loss = 251.77678278491607, acc = 0.6200156372165755\n",
      "iter = 24, loss = 251.77658220474092, acc = 0.6200156372165755\n",
      "iter = 25, loss = 251.77639452450785, acc = 0.6200156372165755\n",
      "iter = 26, loss = 251.77621880006188, acc = 0.6200156372165755\n",
      "iter = 27, loss = 251.77605419335669, acc = 0.6200156372165755\n",
      "iter = 28, loss = 251.7758999299276, acc = 0.6200156372165755\n",
      "iter = 29, loss = 251.7757553242918, acc = 0.6200156372165755\n",
      "iter = 30, loss = 251.77561974989123, acc = 0.6200156372165755\n",
      "iter = 31, loss = 251.77549259836633, acc = 0.6200156372165755\n",
      "iter = 32, loss = 251.77537332338346, acc = 0.6200156372165755\n",
      "iter = 33, loss = 251.77526139496717, acc = 0.6200156372165755\n",
      "iter = 34, loss = 251.7751563387622, acc = 0.6200156372165755\n",
      "iter = 35, loss = 251.77505770683484, acc = 0.6200156372165755\n",
      "iter = 36, loss = 251.774965084946, acc = 0.6200156372165755\n",
      "iter = 37, loss = 251.77487807952494, acc = 0.6200156372165755\n",
      "iter = 38, loss = 251.77479635206004, acc = 0.6200156372165755\n",
      "iter = 39, loss = 251.77471957460025, acc = 0.6200156372165755\n",
      "iter = 40, loss = 251.7746474015755, acc = 0.6200156372165755\n",
      "iter = 41, loss = 251.77457953476758, acc = 0.6200156372165755\n",
      "iter = 42, loss = 251.77451570573044, acc = 0.6200156372165755\n",
      "iter = 43, loss = 251.77445565258185, acc = 0.6200156372165755\n",
      "iter = 44, loss = 251.77439913440125, acc = 0.6200156372165755\n",
      "iter = 45, loss = 251.77434593523157, acc = 0.6200156372165755\n",
      "iter = 46, loss = 251.774295855355, acc = 0.6200156372165755\n",
      "iter = 47, loss = 251.7742487165704, acc = 0.6200156372165755\n",
      "iter = 48, loss = 251.77420435462966, acc = 0.6200156372165755\n",
      "iter = 49, loss = 251.77416259717663, acc = 0.6200156372165755\n",
      "iter = 50, loss = 251.77412328981535, acc = 0.6200156372165755\n",
      "iter = 51, loss = 251.7740862828348, acc = 0.6200156372165755\n",
      "iter = 52, loss = 251.7740514417159, acc = 0.6200156372165755\n",
      "iter = 53, loss = 251.7740186494319, acc = 0.6200156372165755\n",
      "iter = 54, loss = 251.773987792033, acc = 0.6200156372165755\n",
      "iter = 55, loss = 251.7739587638664, acc = 0.6200156372165755\n",
      "iter = 56, loss = 251.7739314533833, acc = 0.6200156372165755\n",
      "iter = 57, loss = 251.77390576465274, acc = 0.6200156372165755\n",
      "iter = 58, loss = 251.77388161286223, acc = 0.6200156372165755\n",
      "iter = 59, loss = 251.77385890255346, acc = 0.6200156372165755\n",
      "iter = 60, loss = 251.7738375544558, acc = 0.6200156372165755\n",
      "iter = 61, loss = 251.77381748616534, acc = 0.6200156372165755\n",
      "iter = 62, loss = 251.77379862183506, acc = 0.6200156372165755\n",
      "iter = 63, loss = 251.7737809011362, acc = 0.6200156372165755\n",
      "iter = 64, loss = 251.77376425641563, acc = 0.6200156372165755\n",
      "iter = 65, loss = 251.77374863194493, acc = 0.6200156372165755\n",
      "iter = 66, loss = 251.77373397265717, acc = 0.6200156372165755\n",
      "iter = 67, loss = 251.77372022464502, acc = 0.6200156372165755\n",
      "iter = 68, loss = 251.77370733630465, acc = 0.6200156372165755\n",
      "iter = 69, loss = 251.7736952595716, acc = 0.6200156372165755\n",
      "iter = 70, loss = 251.7736839486721, acc = 0.6200156372165755\n",
      "iter = 71, loss = 251.77367336247323, acc = 0.6200156372165755\n",
      "iter = 72, loss = 251.77366345847875, acc = 0.6200156372165755\n",
      "iter = 73, loss = 251.77365420017128, acc = 0.6200156372165755\n",
      "iter = 74, loss = 251.77364555230636, acc = 0.6200156372165755\n",
      "iter = 75, loss = 251.773637481405, acc = 0.6200156372165755\n",
      "iter = 76, loss = 251.7736299563916, acc = 0.6200156372165755\n",
      "iter = 77, loss = 251.77362294652232, acc = 0.6200156372165755\n",
      "iter = 78, loss = 251.77361642361106, acc = 0.6200156372165755\n",
      "iter = 79, loss = 251.77361036058335, acc = 0.6200156372165755\n",
      "iter = 80, loss = 251.77360473174642, acc = 0.6200156372165755\n",
      "iter = 81, loss = 251.7735995123658, acc = 0.6200156372165755\n",
      "iter = 82, loss = 251.77359467857434, acc = 0.6200156372165755\n",
      "iter = 83, loss = 251.77359021236455, acc = 0.6200156372165755\n",
      "iter = 84, loss = 251.77358608526438, acc = 0.6200156372165755\n",
      "iter = 85, loss = 251.77358227284728, acc = 0.6200156372165755\n",
      "iter = 86, loss = 251.7735787672601, acc = 0.6200156372165755\n",
      "iter = 87, loss = 251.773575553186, acc = 0.6200156372165755\n",
      "iter = 88, loss = 251.7735726025295, acc = 0.6200156372165755\n",
      "iter = 89, loss = 251.77356990122325, acc = 0.6200156372165755\n",
      "iter = 90, loss = 251.7735674357266, acc = 0.6200156372165755\n",
      "iter = 91, loss = 251.77356519466647, acc = 0.6200156372165755\n",
      "iter = 92, loss = 251.7735631639517, acc = 0.6200156372165755\n",
      "iter = 93, loss = 251.77356133324255, acc = 0.6200156372165755\n",
      "iter = 94, loss = 251.77355969031478, acc = 0.6200156372165755\n",
      "iter = 95, loss = 251.7735582308361, acc = 0.6200156372165755\n",
      "iter = 96, loss = 251.77355694402524, acc = 0.6200156372165755\n",
      "iter = 97, loss = 251.77355581823028, acc = 0.6200156372165755\n",
      "iter = 98, loss = 251.77355483941187, acc = 0.6200156372165755\n",
      "iter = 99, loss = 251.77355399748518, acc = 0.6200156372165755\n",
      "Network of width 10 has 10 nonzero neurons for non-convex weights.\n",
      "CONVEX PROBLEM WEIGHTS:\n",
      "Train loss: 259.6972755201212\n",
      "Train accuracy: 0.6059421422986708\n",
      "Test loss: 61.37048083626514\n",
      "Test accuracy: 0.5875\n",
      "NONCONVEX PROBLEM WEIGHTS:\n",
      "Train loss: 1869.4782727650722\n",
      "Train accuracy: 0.16497263487099295\n",
      "Test loss: 468.2846203294802\n",
      "Test accuracy: 0.190625\n"
     ]
    }
   ],
   "source": [
    "# solve cvx problem\n",
    "\n",
    "solver = Approximate_ReLU_ADMM_Solver(m=10,\n",
    "                                      P_S=10,\n",
    "                                      rho=0.0001,\n",
    "                                      step=0.00001,\n",
    "                                      beta=0.0001,\n",
    "                                      bias=True,\n",
    "                                      loss_func=squared_loss,\n",
    "                                      acc_func=classifcation_accuracy)\n",
    "\n",
    "solver.optimize(X_train, y_train, max_iter=100, verbose=True)\n",
    "\n",
    "\n",
    "print(\"CONVEX PROBLEM WEIGHTS:\")\n",
    "y_hat_train = solver.predict(X_train, weights=\"C-ReLU\")\n",
    "y_hat_test = solver.predict(X_test, weights=\"C-ReLU\")\n",
    "print(f\"Train loss: {squared_loss(y_hat_train, y_train)}\")\n",
    "print(f\"Train accuracy: {classifcation_accuracy(y_hat_train, y_train)}\")\n",
    "print(f\"Test loss: {squared_loss(y_hat_test, y_test)}\")\n",
    "print(f\"Test accuracy: {classifcation_accuracy(y_hat_test, y_test)}\")\n",
    "\n",
    "print(\"NONCONVEX PROBLEM WEIGHTS:\")\n",
    "y_hat_train = solver.predict(X_train, weights=\"NC-ReLU\")\n",
    "y_hat_test = solver.predict(X_test, weights=\"NC-ReLU\")\n",
    "print(f\"Train loss: {squared_loss(y_hat_train, y_train)}\")\n",
    "print(f\"Train accuracy: {classifcation_accuracy(y_hat_train, y_train)}\")\n",
    "print(f\"Test loss: {squared_loss(y_hat_test, y_test)}\")\n",
    "print(f\"Test accuracy: {classifcation_accuracy(y_hat_test, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvx-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
